<!DOCTYPE html>
<html lang="en">
  <head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="">
<link rel="shortcut icon" href="../../docs-assets/ico/favicon.png">

<title>Roshan Rao</title>

<!-- Bootstrap core CSS -->
<link href="assets/css/bootstrap.css" rel="stylesheet">


<!-- Custom styles for this template -->
<link href="assets/css/main.css" rel="stylesheet">

<script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
<script src="assets/js/hover.zoom.js"></script>
<script src="assets/js/hover.zoom.conf.js"></script>

<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
<![endif]-->
</head>

<body>

<!-- Static navbar -->
<div class="navbar navbar-inverse navbar-static-top">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="./">ROSHAN RAO</a>
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right img-aligner">
        <li><a href="#Papers">Papers</a></li>
        <li><a href="https://github.com/rmrao"><img class="img-icon" src="assets/img/github_logo.png"></a></li>
        <li><a href="https://twitter.com/proteinrosh"><img class="img-icon" src="assets/img/twitter_logo.png"></a></li>
        <li><a href="https://www.linkedin.com/in/roshanrao1/"><img class="img-icon" src="assets/img/linkedin_logo.png"></a></li>
        <!--<li><a href="index.html#Contact">Contact</a></li>-->
      </ul>
    </div><!--/.nav-collapse -->
  </div>
</div>

<!-- +++++ Welcome Section +++++ -->
<div id="ww">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 centered">
                <img class="img-circle" src="assets/img/me.jpg" alt="Roshan Rao">

                <p>I am a co-founder and research scientist at EvolutionaryScale, working on evolutionary models of proteins. Previously, I worked at Meta AI and completed my PhD at <a href=https://eecs.berkeley.edu/>UC Berkeley</a>, where I was advised by <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/canny.html"/>John Canny</a> and <a href="https://people.eecs.berkeley.edu/~pabbeel/"/>Pieter Abbeel</a> Check out <a href="https://www.youtube.com/watch?v=hcJS9d09ECA">my dissertation talk</a> for an introduction to this area of research and an overview of my past work!</p>

            </div><!-- /col-lg-8 -->
        </div><!-- /row -->
    </div> <!-- /container -->
</div><!-- /ww -->


<!-- +++++ Projects Section +++++ -->
<div class="container pt">

    <div class="row">
        <div class="col-lg-10 col-lg-offset-1" style="padding-bottom: 3em; text-align: center;">
        <h3 class="section-title" id="Talks">Talks</h3>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/hcJS9d09ECA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>

        <div class="col-lg-10 col-lg-offset-1">
        <h3 class="section-title" id="Papers">All Papers</h3>
        <div>
            
            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/esm3_arch.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">Simulating 500 million years of evolution with a language model</p>
                        <p class="conference">Preprint 2024.</p>
                        <p class="authors">Thomas Hayes,</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Halil Akin,</p>
                        <p class="authors">Nicholas J. Sofroniew,</p>
                        <p class="authors">Deniz Oktay,</p>
                        <p class="authors">Zeming Lin,</p>
                        <p class="authors">Robert Verkuil,</p>
                        <p class="authors">Vincent Q. Tran,</p>
                        <p class="authors">Jonathan Deaton,</p>
                        <p class="authors">Marius Wiggert,</p>
                        <p class="authors">Rohil Badkundri,</p>
                        <p class="authors">Irhum Shafkat,</p>
                        <p class="authors">Jun Gong,</p>
                        <p class="authors">Alexander Derry,</p>
                        <p class="authors">Raul S. Molina,</p>
                        <p class="authors">Neil Thomas,</p>
                        <p class="authors">Yousuf Khan,</p>
                        <p class="authors">Chetan Mishra,</p>
                        <p class="authors">Carolyn Kim,</p>
                        <p class="authors">Liam J. Bartie,</p>
                        <p class="authors">Matthew Nemeth,</p>
                        <p class="authors">Patrick D. Hsu,</p>
                        <p class="authors">Tom Sercu,</p>
                        <p class="authors">Salvatore Candido,</p>
                        <p class="authors">Alexander Rives</p>
                        <div class="social">
                            <a href="https://evolutionaryscale-public.s3.us-east-2.amazonaws.com/research/esm3.pdf" target="_blank">Paper</a>
                            <a href="https://github.com/evolutionaryscale/esm" target="_blank">Github</a>
                            <a href="https://evolutionaryscale.ai/blog/esm3-release" target="_blank">Blog</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">
                            More than three billion years of evolution have
                            produced an image of biology encoded into the
                            space of natural proteins. Here we show that language models trained on tokens generated by evolution can act as evolutionary simulators to generate functional proteins that are far away from
                            known proteins. We present ESM3, a frontier
                            multimodal generative language model that reasons over the sequence, structure, and function
                            of proteins. ESM3 can follow complex prompts
                            combining its modalities and is highly responsive
                            to biological alignment. We have prompted ESM3
                            to generate fluorescent proteins with a chain of
                            thought. Among the generations that we synthesized, we found a bright fluorescent protein at far
                            distance (58% identity) from known fluorescent
                            proteins. Similarly distant natural fluorescent proteins are separated by over five hundred million
                            years of evolution.
                        </p>
                    </div>
                </div>
             </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/generations.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">A high-level programming language for generative protein design</p>
                        <p class="conference">bioRxiv 2022.</p>
                        <p class="authors">Brian Hie,</p>
                        <p class="authors">Salvatore Candido,</p>
                        <p class="authors">Zeming Lin,</p>
                        <p class="authors">Ori Kabeli,</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Nikita Smetanin,</p>
                        <p class="authors">Tom Sercu,</p>
                        <p class="authors">Alexander Rives</p>
                        <div class="social">
                            <a href="https://doi.org/10.1101/2022.12.21.521526" target="_blank">bioRxiv</a>
                            <a href="https://github.com/facebookresearch/esm" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">Combining a basic set of building blocks into more complex forms is a universal design principle. Most protein designs have proceeded from a manual bottom-up approach using parts created by nature, but top-down design of proteins is fundamentally hard due to biological complexity. We demonstrate how the modularity and programmability long sought for protein design can be realized through generative artificial intelligence. Advanced protein language models demonstrate emergent learning of atomic resolution structure and protein design principles. We leverage these developments to enable the programmable design of de novo protein sequences and structures of high complexity. First, we describe a high-level programming language based on modular building blocks that allows a designer to easily compose a set of desired properties. We then develop an energy-based generative model, built on atomic resolution structure prediction with a language model, that realizes all-atom structure designs that have the programmed properties. Designing a diverse set of specifications, including constraints on atomic coordinates, secondary structure, symmetry, and multimerization, demonstrates the generality and controllability of the approach. Enumerating constraints at increasing levels of hierarchical complexity shows that the approach can access a combinatorially large design space.</p>
                    </div>
                </div>
             </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/atlas_nearest.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">Evolutionary-scale prediction of atomic level protein structure with a language model</p>
                        <p class="conference">Science 2023.</p>
                        <p class="authors">Zeming Lin,</p>
                        <p class="authors">Halil Akin,</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Brian Hie,</p>
                        <p class="authors">Zhongkai Zhu,</p>
                        <p class="authors">Wenting Lu,</p>
                        <p class="authors">Nikita Smetanin,</p>
                        <p class="authors">Robert Verkuil,</p>
                        <p class="authors">Ori Kabeli,</p>
                        <p class="authors">Yaniv Shmueli,</p>
                        <p class="authors">Allan dos Santos Costa,</p>
                        <p class="authors">Maryam Fazel-Zarandi,</p>
                        <p class="authors">Tom Sercu,</p>
                        <p class="authors">Salvatore Candido,</p>
                        <p class="authors">Alexander Rives</p>
                        <div class="social">
                            <a href="https://doi.org/10.1101/2022.07.20.500902" target="_blank">bioRxiv</a>
                            <a href="https://github.com/facebookresearch/esm" target="_blank">Github</a>
                            <a href="https://esmatlas.com/" target="_blank">ESM Atlas</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">Artificial intelligence has the potential to open insight into the structure of proteins at the scale of evolution. It has only recently been possible to extend protein structure prediction to two hundred million cataloged proteins. Characterizing the structures of the exponentially growing billions of protein sequences revealed by large scale gene sequencing experiments would necessitate a break-through in the speed of folding. Here we show that direct inference of structure from primary sequence using a large language model enables an order of magnitude speed-up in high resolution structure prediction. Leveraging the insight that language models learn evolutionary patterns across millions of sequences, we train models up to 15B parameters, the largest language model of proteins to date. As the language models are scaled they learn information that enables prediction of the three-dimensional structure of a protein at the resolution of individual atoms. This results in prediction that is up to 60x faster than state-of-the-art while maintaining resolution and accuracy. Building on this, we present the ESM Metage-nomic Atlas. This is the first large-scale structural characterization of metagenomic proteins, with more than 617 million structures. The atlas reveals more than 225 million high confidence predictions, including millions whose structures are novel in comparison with experimentally determined structures, giving an unprecedented view into the vast breadth and diversity of the structures of some of the least understood proteins on earth.</p>
                    </div>
                </div>
             </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/generations.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">A high-level programming language for generative protein design</p>
                        <p class="conference">bioRxiv 2022.</p>
                        <p class="authors">Brian Hie,</p>
                        <p class="authors">Salvatore Candido,</p>
                        <p class="authors">Zeming Lin,</p>
                        <p class="authors">Ori Kabeli,</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Nikita Smetanin,</p>
                        <p class="authors">Tom Sercu,</p>
                        <p class="authors">Alexander Rives</p>
                        <div class="social">
                            <a href="https://doi.org/10.1101/2022.12.21.521526" target="_blank">bioRxiv</a>
                            <a href="https://github.com/facebookresearch/esm" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">Combining a basic set of building blocks into more complex forms is a universal design principle. Most protein designs have proceeded from a manual bottom-up approach using parts created by nature, but top-down design of proteins is fundamentally hard due to biological complexity. We demonstrate how the modularity and programmability long sought for protein design can be realized through generative artificial intelligence. Advanced protein language models demonstrate emergent learning of atomic resolution structure and protein design principles. We leverage these developments to enable the programmable design of de novo protein sequences and structures of high complexity. First, we describe a high-level programming language based on modular building blocks that allows a designer to easily compose a set of desired properties. We then develop an energy-based generative model, built on atomic resolution structure prediction with a language model, that realizes all-atom structure designs that have the programmed properties. Designing a diverse set of specifications, including constraints on atomic coordinates, secondary structure, symmetry, and multimerization, demonstrates the generality and controllability of the approach. Enumerating constraints at increasing levels of hierarchical complexity shows that the approach can access a combinatorially large design space.</p>
                    </div>
                </div>
             </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/mlm-scoring.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">Language models enable zero-shot prediction of the effects of mutations on protein function</p>
                        <p class="conference">NeurIPS 2021.</p>
                        <p class="authors">Joshua Meier,</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Robert Verkuil,</p>
                        <p class="authors">Jason Liu,</p>
                        <p class="authors">Tom Sercu,</p>
                        <p class="authors">Alexander Rives</p>
                        <div class="social">
                            <a href="https://www.biorxiv.org/content/10.1101/2021.07.09.450648v1.full" target="_blank">bioRxiv</a>
                            <a href="https://github.com/facebookresearch/esm" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">Modeling the effect of sequence variation on function is a fundamental problem for understanding and designing proteins. Since evolution encodes information about function into patterns in protein sequences, unsupervised models of variant effects can be learned from sequence data. The approach to date has been to fit a model to a family of related sequences. The conventional setting is limited, since a new model must be trained for each prediction task. We show that using only zero-shot inference, without any supervision from experimental data or additional training, protein language models capture the functional effects of sequence variation, performing at state-of-the-art.</p>
                    </div>
                </div>
             </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/4zjp_1_A.gif">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">MSA Transformer</p>
                        <p class="conference">ICML 2021.</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Jason Liu,</p>
                        <p class="authors">Robert Verkuil,</p>
                        <p class="authors">Joshua Meier,</p>
                        <p class="authors">John Canny,</p>
                        <p class="authors">Pieter Abbeel,</p>
                        <p class="authors">Tom Sercu,</p>
                        <p class="authors">Alexander Rives</p>
                        <div class="social">
                            <a href="https://www.biorxiv.org/content/10.1101/2021.02.12.430858v1" target="_blank">bioRxiv</a>
                            <a href="https://github.com/facebookresearch/esm" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">Unsupervised protein language models trained across millions of diverse sequences learn structure and function of proteins. Protein language models studied to date have been trained to perform inference from individual sequences. The longstanding approach in computational biology has been to make inferences from a family of evolutionarily related sequences by fitting a model to each family independently. In this work we combine the two paradigms. We introduce a protein language model which takes as input a set of sequences in the form of a multiple sequence alignment. The model interleaves row and column attention across the input sequences and is trained with a variant of the masked language modeling objective across many protein families. The performance of the model surpasses current state-of-the-art unsupervised structure learning methods by a wide margin, with far greater parameter efficiency than prior state-of-the-art protein language models.</p>
                    </div>
                </div>
             </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/logistic_regression.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">Transformer protein language models are unsupervised structure learners</p>
                        <p class="conference">ICLR 2021.</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Joshua Meier,</p>
                        <p class="authors">Tom Sercu,</p>
                        <p class="authors">Sergey Ovchinnikov,</p>
                        <p class="authors">Alexander Rives</p>
                        <div class="social">
                            <a href="https://www.biorxiv.org/content/10.1101/2020.12.15.422761v1" target="_blank">bioRxiv</a>
                            <a href="https://github.com/facebookresearch/esm" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">Unsupervised contact prediction is central to uncovering physical, structural, and functional constraints for protein structure determination and design. For decades, the predominant approach has been to infer evolutionary constraints from a set of related sequences. In the past year, protein language models have emerged as a potential alternative, but performance has fallen short of state-of-the-art approaches in bioinformatics. In this paper we demonstrate that Transformer attention maps learn contacts from the unsupervised language modeling objective. We find the highest capacity models that have been trained to date already outperform a state-of-the-art unsupervised contact prediction pipeline, suggesting these pipelines can be replaced with a single forward pass of an end-to-end model.</p>
                    </div>
                </div>
            </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/single-layers.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">Single Layers of Attention Suffice to Predict Protein Contacts</p>
                        <p class="conference">bioRxiv 2020.<p/>
                        <p class="authors">Nicholas Bhattacharya*,</p>
                        <p class="authors">Neil Thomas*,</p>
                        <p class="me_author">Roshan Rao,</p>
                        <p class="authors">Justas Dauparas,</p>
                        <p class="authors">Peter K. Koo,</p>
                        <p class="authors">David Baker,</p>
                        <p class="authors">Sergey Ovchinnikov</p>
                        <div class="social">
                            <a href="https://www.biorxiv.org/content/10.1101/2020.12.21.423882v2" target="_blank">bioRxiv</a>
                            <a href="https://github.com/nickbhat/mogwai" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">The established approach to unsupervised protein contact prediction estimates co-evolving positions using undirected graphical models. This approach trains a Potts model on a Multiple Sequence Alignment, then predicts that the edges with highest weight correspond to contacts in the 3D structure. On the other hand, increasingly large Transformers are being pretrained on protein sequence databases but have demonstrated mixed results for downstream tasks, including contact prediction. This has sparked discussion about the role of scale and attention-based models in unsupervised protein representation learning. We argue that attention is a principled model of protein interactions, grounded in real properties of protein family data. We introduce a simplified attention layer, factored attention, and show that it achieves comparable performance to Potts models, while sharing parameters both within and across families. Further, we extract contacts from the attention maps of a pretrained Transformer and show they perform competitively with the other two approaches. This provides evidence that large-scale pretraining can learn meaningful protein features when presented with unlabeled and unaligned data. We contrast factored attention with the Transformer to indicate that the Transformer leverages hierarchical signal in protein family databases not captured by our single-layer models. This raises the exciting possibility for the development of powerful structured models of protein family databases.</p>
                    </div>
                </div>
            </article>

            <article class="paper">
                <div class="row paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/protein-tape.png">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">Evaluating Protein Transfer Learning with TAPE</p>
                        <p class="conference">NeurIPS 2019. <span class="award">Spotlight.</span></p>
                        <p class="me_author">Roshan Rao*,</p>
                        <p class="authors">Nicholas Bhattacharya*,</p>
                        <p class="authors">Neil Thomas*,</p>
                        <p class="authors">Yan Duan,</p><br/>
                        <p class="authors">Xi Chen,</p>
                        <p class="authors">John Canny,</p>
                        <p class="authors">Pieter Abbeel,</p>
                        <p class="authors">Yun S. Song</p>
                        <div class="social">
                            <a href="https://www.biorxiv.org/content/10.1101/676825v1" target="_blank">bioRxiv</a>
                            <a href="https://github.com/songlab-cal/TAPE" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">Protein modeling is an increasingly popular area of machine learning research. Semi-supervised learning has emerged as an important paradigm in protein modeling due to the high cost of acquiring supervised protein labels, but the current literature is fragmented when it comes to datasets and standardized evaluation techniques. To facilitate progress in this field, we introduce the Tasks Assessing Protein Embeddings (TAPE), a set of five biologically relevant semi-supervised learning tasks spread across different domains of protein biology. We curate tasks into specific training, validation, and test splits to ensure that each task tests biologically relevant generalization that transfers to real-life scenarios. We bench-mark a range of approaches to semi-supervised protein representation learning, which span recent work as well as canonical sequence learning techniques. We find that self-supervised pretraining is helpful for almost all models on all tasks, more than doubling performance in some cases. Despite this increase, in several cases features learned by self-supervised pretraining still lag behind features extracted by state-of-the-art non-neural techniques. This gap in performance suggests a huge opportunity for innovative architecture design and improved modeling paradigms that better capture the signal in biological sequences. TAPE will help the machine learning community focus effort on scientifically relevant problems. Toward this end, all data and code used to run these experiments are available at <a href=https://github.com/songlab-cal/tape>https://github.com/songlab-cal/tape</a>.</p>
                    </div>
                </div>
            </article>

            <article class="paper">
                <div class="paper-block">
                    <div class="col-lg-3">
                        <img class="img-fluid paper-image" src="assets/img/tsne.gif">
                    </div>
                    <div class="col-lg-9 paper-meta">
                        <p class="title">GPU-Accelerated t-SNE and its Applications to Modern Data</p>
                        <p class="conference">High Performance Machine Learning (HPML) 2018. <span class="award">Outstanding Paper Award.</span></p>
                        <p class="authors">David Chan*,</p>
                        <p class="me_author">Roshan Rao*,</p>
                        <p class="authors">Forrest Huang*,</p>
                        <p class="authors">John Canny</p>
                        <div class="social">
                            <a href="https://arxiv.org/abs/1807.11824" target="_blank">arXiv</a>
                            <a href="https://github.com/CannyLab/tsne-cuda" target="_blank">Github</a>
                        </div>
                    </div>
                    <div class="col-lg-12 paper-desc">
                        <p class="abstract">This paper introduces t-SNE-CUDA, a GPU-accelerated implementation of t-distributed Symmetric Neighbor Embedding (t-SNE) for visualizing datasets and models. t-SNE-CUDA significantly outperforms current implementations with 50-700x speedups on the CIFAR-10 and MNIST datasets. These speedups enable, for the first time, visualization of the neural network activations on the entire ImageNet dataset - a feat that was previously computationally intractable. We also demonstrate visualization performance in the NLP domain by visualizing the GloVe embedding vectors. From these visualizations, we can draw interesting conclusions about using the L2 metric in these embedding spaces.</p>
                    </div>
                 </div>
            </article>
        </div>
        </div>
		</div><!-- /row -->
	</div><!-- /container -->


	<!-- +++++ Footer Section +++++ -->

	<footer class="footer" id="footer">
		<div class="container">

			<div class="row">
                <ul class="footer-contact">
                    <li class="contact">rmrao at meta.com<span class="divider">|</span></li>
                    <li class="contact">New York, NY.</li>
                </ul>

			</div>

		</div>
	</footer>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="assets/js/more.js"></script>
    <script src="assets/node_modules/readmore-js/readmore.js"></script>
    <script>$('article').readmore({
      collapsedHeight: 210,
      speed: 200,
        moreLink: '<span class="readmore-lnk"><a href="#">Read more</a></span>',
        lessLink: '<span class="readmore-lnk"><a href="#">Close</a></span>'
    });
    </script>
  </body>
</html>
